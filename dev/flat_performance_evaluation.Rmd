---
title: "flat_performance_evaluation.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
library(assertthat)
library(dplyr)
library(PropCIs)
library(checkmate)
```

<!--
 You need to run the 'description' chunk in the '0-dev_history.Rmd' file before continuing your code there.
-->
## sens_spe_for_forest 

Calculates sensitivity and specificity of a diagnostic test.
Results are formatted to generate forest plots.
    
```{r function-sens_spe_for_forest}
#' Sensitivity and specificity (for forest plots)
#' 
#' Calculate sensitivity and specificity with confidence intervals from a data frame that contains the results of the index and the reference test. 
#' To be used for displaying the result in a forest plot.
#' 
#' @param data_var Data table containing test results
#' @param index The index test with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha -- default 95%
#'
#' @return A data table with TP/FP/TN/FN, sensitivity, specificity and confidence intervals
#' @import dplyr
#' @import assertthat 
#' @import PropCIs
#' 
#' @export
sens_spe_for_forest <- function(data_var, index, ref, conf.level = 0.95){
  #verify that these are column names in characters
  assert_that(is.character(index))
  assert_that(is.character(ref))

  # Calculate number of TP, TN, FP, FN, etc.
  TP	<- nrow(data_var[which(data_var[,index] == "Positive" & data_var[,ref] == "Positive"),])
  FP	<- nrow(data_var[which(data_var[,index] == "Positive" & data_var[,ref] == "Negative"),])
  FN	<- nrow(data_var[which(data_var[,index] == "Negative" & data_var[,ref] == "Positive"),])
  TN	<- nrow(data_var[which(data_var[,index] == "Negative" & data_var[,ref] == "Negative"),])

  sens	<- round((TP / (TP + FN))*100, 2)
  sens_CI	<- scoreci(x = TP, n  = (TP + FN), conf.level = conf.level)

  spe		<- round((TN / (TN +FP))*100,2)
  spe_CI	<- scoreci(x = TN, n  = (TN + FP), conf.level = conf.level)
  BA <- round((sens+spe)/2, 2)
  BA_lci <- round((sens_CI$conf.int[1]*100 + spe_CI$conf.int[1]*100)/2, 2)
  BA_hci <- round((sens_CI$conf.int[2]*100 + spe_CI$conf.int[2]*100)/2, 2)
  DOR <- round((TP*TN)/(FP*FN), 2)
  se_dor <- sqrt((1/TP+1/FN+1/FP+1/TN))
  z <- qnorm(1-conf.level/2) 
  DOR_lci <- round(exp(log(DOR) - z*se_dor), 2)
  DOR_hci <- round(exp(log(DOR) + z*se_dor), 2)

  PPV	<- round((TP / (TP + FP))*100, 2)
  ppv_CI	<- scoreci(x = TP, n  = (TP + FP), conf.level = conf.level)
  NPV	<- round((TN / (TN + FN))*100,2)
  npv_CI	<- scoreci(x = TN, n  = (TN + FN), conf.level = conf.level)

  ACC	<- round(((TP + TN) / (TP + FP + FN + TN))*100,2)
  acc_CI	<- scoreci(x = (TP + TN), n  = (TP + FP + FN + TN), conf.level = conf.level)

  N 		<- TP + TN + FP + FN

  data_to_return_1	<- data.frame(N = N, TP = TP, FP = FP, FN = FN, TN = TN,
                                 Sensitivity = sens, Specificity = (spe),
                                 SensLower = (sens_CI$conf.int[1])*100,
                                 SensUpper = (sens_CI$conf.int[2])*100,
                                 SpeLower = (spe_CI$conf.int[1])*100,
                                 SpeUpper = (spe_CI$conf.int[2])*100,
                                 Balanced_Accuracy = BA,
                                 BAlower = BA_lci,
                                 BAupper = BA_hci,
                                 DOR = DOR,
                                 DORUpper = DOR_hci,
                                 DORLower = DOR_lci,
                                 PPV = PPV,
                                 PPVLower = (ppv_CI$conf.int[1])*100,
                                 PPVUpper = (ppv_CI$conf.int[2])*100,
                                 NPV = NPV,
                                 NPVLower = (npv_CI$conf.int[1])*100,
                                 NPVUpper = (npv_CI$conf.int[2])*100,
                                 Accuracy = ACC,
                                 ACCLower = (acc_CI$conf.int[1])*100,
                                 ACCUpper = (acc_CI$conf.int[2])*100)
  return(data_to_return_1)
}




```
  
```{r example-sens_spe_for_forest}
library(forestplot)
library(dplyr)
df <- data.frame(Index = c(rep("Positive", 20), rep("Negative", 20)), Reference = c(rep("Positive", 30), rep("Negative", 10)))
forest_data <- cbind(Test = "Index", sens_spe_for_forest(data_var = df, index = "Index", ref = "Reference", conf.level = 0.95))
forest_data %>% forestplot(mean = Sensitivity, 
                          lower = SensLower, 
                          upper = SensUpper, 
                          labeltext = Test,
                          title = "Sensitivity",
                          zero = NA,
                          xticks = c( 0, 20, 40, 60, 80, 100),
                          txt_gp = fpTxtGp(ticks=gpar(cex=1)),
                          boxsize = .1
                          )
```
  
```{r tests-sens_spe_for_forest}
  df <- data.frame(Index = c(rep("Positive", 20), rep("Negative", 20)), Reference = c(rep("Positive", 10), rep("Negative", 30)))
test_that("sen_spe_for_forest works", {
 expect_error( sens_spe_for_forest(
    data_var = df,
    index = 0.8,
    ref = "Reference",
    conf.level = 0.95
  ))
})
```
  
## sens_spe

Calculates sensitivity and specificity of a diagnostic test.
Results are formatted to generate a table to display.
    
```{r function-sens_spe}
#' Sensitivity and specificity (Table Display)
#' 
#' Calculate sensitivity and specificity with confidence intervals from a data frame that contains the results of the index and the reference test. 
#' To be used for displaying the result in a table.
#' 
#' @param data_var Data table containing test results
#' @param index The index test with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha -- default 95%
#'
#' @return A data table with TP/FP/TN/FN, sensitivity, specificity and confidence intervals
#' @import dplyr
#' @import assertthat 
#' @import PropCIs
#' @export
sens_spe <- function(data_var, index, ref, conf.level = 0.95){
  #verify that these are column names in characters
  assert_that(is.character(index))
  assert_that(is.character(ref))

  # Calculate number of TP.

table <- sens_spe_for_forest(data_var = data_var, index = index, ref = ref, conf.level = 0.95)

  sens_ci_text <- paste0('[', format(table$SensLower, nsmall = 1), '-', format(table$SensUpper, nsmall = 1), ']')
  spe_ci_text  <- paste0('[', format(table$SpeLower, nsmall = 1), '-', format(table$SpeUpper, nsmall = 1), ']')
  BA_ci_text   <- paste0('[', format(table$BAlower, nsmall = 1), '-', format(table$BAupper, nsmall = 1), ']')
  DOR_ci_text   <- paste0('[', format(table$DORLower, nsmall = 1), '-', format(table$DORUpper, nsmall = 1), ']')
  ppv_ci_text <- paste0('[', format(table$PPVLower, nsmall = 1), '-', format(table$PPVUpper, nsmall = 1), ']')
  npv_ci_text  <- paste0('[', format(table$NPVLower, nsmall = 1), '-', format(table$NPVUpper, nsmall = 1), ']')
  acc_ci_text   <- paste0('[', format(table$ACCLower, nsmall = 1), '-', format(table$ACCUpper, nsmall = 1), ']')


  data_to_return_1	<- c(N = table$N, TP = table$TP, FP = table$FP, FN = table$FN, TN = table$TN, `Sensitivity` = table$Sensitivity, `Sensitivity [95%CI]` = sens_ci_text, `Specificity` = table$Specificity, `Specificity [95%CI]` = spe_ci_text, `Balanced Accuracy` = table$Balanced_Accuracy, `B. Accuracy [95%CI]` = BA_ci_text, `DOR` = table$DOR, `DOR [95%CI]` = DOR_ci_text, PPV = table$PPV, `PPV [95%CI]` = ppv_ci_text, NPV = table$NPV, `NPV [95%CI]` = npv_ci_text, Accuracy = table$Accuracy, `Accuracy [95%CI]` = acc_ci_text )
  names_tp <- names(data_to_return_1)
  data_to_return_1  <- data.frame(t(data_to_return_1))
  colnames(data_to_return_1) <- names_tp
  return(data_to_return_1)
}
```
  
```{r example-sens_spe}
df <- data.frame(Index = c(rep("Positive", 5), rep("Negative", 30), rep("Positive", 5)), Reference = c(rep("Positive", 10), rep("Negative", 30)))
sens_spe(data_var = df, index = "Index", ref = "Reference", conf.level = 0.95)
```
  
```{r tests-sens_spe}
  df <- data.frame(Index = c(rep("Positive", 20), rep("Negative", 20)), Reference = c(rep("Positive", 10), rep("Negative", 30)))
test_that("sen_spe works", {
 expect_error( sens_spe(
    data_var = df,
    index = 0.8,
    ref = "Reference",
    conf.level = 0.95
  ))
})
```
  

## CI_Calc
Calculates the confidence interval of a given proportion with normal approximation.
    
```{r function-CI_Calc}
#' Confidence Interval Calculator
#' 
#' Calculates the confidence interval of a given proportion with normal approximation.
#' 
#' @param alpha significance level
#' @param proportion the proportion
#' @param n sample size
#'
#' @return confidence interval lower and upper bounds
#' 
#' @importFrom checkmate expect_number
#' @importFrom stats qnorm
#' @export
CI_Calc <- function(alpha, proportion, n){
  alpha_val         <- 1-alpha/2
  z = qnorm(alpha_val)
  ci = z*sqrt((proportion*(1-proportion))/n)
  return(round(ci, digits = 4))
}
```
  
```{r example-CI_Calc}
CI_Calc(alpha=0.05, proportion=0.62, n= 500)
```
  
```{r tests-CI_Calc}
test_that("CI_calc works", expect_number(CI_Calc(alpha=0.05, proportion=0.8, n= 321)))
```
  

## multi_sen_spe
    
To create a data frame that shows performance characteristics of multiple tests.
    
```{r function-multi_sen_spe}
#' multi_sen_spe for Table Display
#' 
#' Calculates and displays sensitivity and specificity with confidence intervals from a data frame for multiple index tests and the reference test. To be used for displaying the result in a table.
#' 
#' @param data_var Data table containing tests results
#' @param list_index A list of index tests with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha – default 95%
#' @param index_names An optional list containing names of the index tests
#'
#' @return A data table with TP/FP/TN/FN, sensitivity, specificity and confidence intervals for all index tests specified in the list
#' 
#' @export
multi_sen_spe <- function(data_var, list_index, ref, conf.level = 0.95, index_names = NULL){
    performance_display <- data.frame()
  for(i in list_index){
    df <- sens_spe(data_var = data_var, index = i, ref = ref, conf.level = conf.level)
    performance_display <- rbind(performance_display, df)
  }
    ifelse(
    is.null(index_names),
    rownames(performance_display) <-
      list_index,
    rownames(performance_display) <- index_names
  )
  return(performance_display)
}
```
  
```{r example-multi_sen_spe}
library(finddataanalysis)
df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))

multi_sen_spe(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, index_names = c("a", "b", "c"))


```
  
```{r tests-multi_sen_spe}
library(finddataanalysis)

df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))

test_that("multi_sen_spe works", {
  expect_true(is.data.frame(multi_sen_spe(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95))) 
})
```

## multi_sen_spe_forest

To create a data frame that is forest plot friendly with multiple index tests
    
```{r function-multi_sen_spe_forest}
#' multi_sen_spe_forest for forest plots
#' 
#' Calculates and displays sensitivity and specificity with confidence intervals from a data frame for multiple index tests and the reference test. To be used for displaying the result in a table.
#' 
#' @param data_var  Data table containing test results
#' @param list_index A list of index test with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha – default 95%
#' @param index_names An optional list containing names of the index tests
#'
#' @return A data table with TP/FP/TN/FN, sensitivity, specificity and confidence intervals, to be fed into forestplot function.
#' 
#' @export
multi_sen_spe_forest <- function(data_var, list_index, ref, conf.level = 0.95, index_names = NULL){
  data_to_forest <- data.frame()
  for (i in list_index){
      df <- sens_spe_for_forest(data_var, i, ref, conf.level = 0.95)
      data_to_forest <- rbind(data_to_forest, df)
  }
  ifelse(
    is.null(index_names),
    data_to_forest$Test <-
      list_index,
    data_to_forest$Test <- index_names
  )
    return(data_to_forest)
}
```
  
```{r example-multi_sen_spe_forest}

df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))

multi_sen_spe_forest(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, index_names = c("ate","FNDH", "DXCb"))
```
  
```{r tests-multi_sen_spe_forest}

df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))

test_that("multi_sen_spe_forest works", {
  expect_true(is.data.frame(multi_sen_spe_forest(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95))) 
})

```
      
## multi_sen_spe_dt_out

Calculate performance characteristics and generate a nice table output.
    
```{r function-multi_sen_spe_dt_out}
#' multi_sen_spe with DT table output
#' 
#' Executes multi_sen_spe function and creates a nicely formatted table output with download options using DT package
#' 
#' @param data_var Data table containing tests results
#' @param list_index A list of index tests with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha – default 95%
#' @param index_names An optional list containing names of the index tests
#' @param file_name  An optional text containing the name of the file that will be downloaded
#'
#' @return A formatted data table displaying performance characteristics
#' @importFrom DT datatable
#' @export
multi_sen_spe_dt_out <- function(data_var, list_index, ref, conf.level = 0.95, index_names = NULL, file_name="performance_eval"){
    
  datatable(multi_sen_spe(data_var, list_index = list_index, ref = ref, index_names = index_names, conf.level=conf.level ),
                  extensions = 'Buttons',
                  options = list(dom = 'Blfrtip',
                                 buttons = list(
                                   list(extend = 'copy', filename = file_name),
                                   list(extend = 'csv', filename = file_name),
                                   list(extend = 'excel', filename = file_name),
                                   list(extend = 'pdf', filename = file_name)),
                                 lengthMenu = list(c(10,-1),
                                                   c(10,"All"))))

}
```
  
```{r example-multi_sen_spe_dt_out}
df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))


multi_sen_spe_dt_out(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, file_name = "ZX001_performance", index_names = c("a", "b", "c"))
```
  
```{r tests-multi_sen_spe_dt_out}
test_that("multi_sen_spe_dt_out works", {
  expect_true(inherits(multi_sen_spe_dt_out, "function")) 
})
```
   

## multi_sen_spe_out_forest

Calculate performance characteristics and generate a nice forestplots.

    
```{r function-multi_sen_spe_out_forest}
#' multi_sen_spe with forest plot output
#' 
#' Executes multi_sen_spe function and creates forest plots automatically. 
#' 
#' @param data_var Data table containing tests results
#' @param list_index A list of index tests with "Negative" and "Positive" results
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha – default 95%
#' @param index_names An optional list containing names of the index tests
#' @param labels An optional text for the axis label
#' 
#' @return Interactive forest plots in a list
#' 
#' @export
#' @import ggplot2

#' @import plotly

multi_sen_spe_out_forest <- function(data_var, list_index, ref, conf.level = 0.95, index_names = NULL, labels = "Tests"){
  
  perf_forest <- multi_sen_spe_forest(
  data_var = data_var,
  list_index = list_index,
  ref = ref,
  conf.level = conf.level,
  index_names = index_names
)



fp_sen <- ggplot(data=perf_forest, aes(x=Test, y=Sensitivity, ymin=SensLower, ymax=SensUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Sensitivity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)

fp_spe <- ggplot(data=perf_forest, aes(x=Test, y=Specificity, ymin=SpeLower, ymax=SpeUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Specificity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)


forestplots <- list(ggplotly(fp_sen), ggplotly(fp_spe))

return(forestplots)
    
}
```
  
```{r example-multi_sen_spe_out_forest}
df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))
plots <- multi_sen_spe_out_forest(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, labels = "Index Tests", index_names = c("a", "b", "c"))
plots[[1]]
plots[[2]]
```
  
```{r tests-multi_sen_spe_out_forest}
test_that("multi_sen_spe_out_forest works", {
  expect_true(inherits(multi_sen_spe_out_forest, "function")) 
})
```
  
# performance_eval_auto

Executes an automatized analysis of performance evaluation. The function calculates sensitivity, specificity, balanced accuracy, diagnostic odds ratio, negative and positive predictive values. It generates downloadable tables and interactive graphs based on the parameters that are entered. There are also options to get a simple, unformatted version of the table containing the result.
For long data, a grouping variable needs to be defined. The column name feeds into dplyr later on, and should be entered without quotation marks.  
For wide data column names containing index tests should be entered as a list.
The reference should always be in a separate column.
    
```{r function-performance_eval_auto}
#' performance_eval_auto
#' 
#' Calculates diagnostic accuracy characteristics and generates report quality tables and figures. Executes multi_sen_spe_out_forest, multi_sen_spe_dt_out, and returns a list object with two forest plots and a DT data table for display.The function works with wide and long formats.
#' 
#' @return performance evaluation results as plots, formatted table, or simple data frame
#' 
#' @param data_var Data table containing tests results
#' @param list_index A list of index tests with "Negative" and "Positive" results. If the data is in long format, the name of the column where the results are stored.
#' @param ref The reference test with "Negative" and "Positive" results
#' @param conf.level The confidence level, 1-alpha – default 95%
#' @param index_names An optional list containing names of the index tests. Not used with long data format.
#' @param forest_plot Should the forest plots be generated? Default TRUE
#' @param table_output Should a table output be generated? Default TRUE
#' @param data_long Is the data in the long format? Default FALSE
#' @param labels An optional text for the axis labels in forest plots.
#' @param file_name An optional text for the file name that will be available for download when the table output is generated
#' @param group_var The variable name where the groups are defined. Enter without quotation marks (e.g. ColName instead of "ColName"). Not used with wide data format.
#' 
#' @import ggplot2
#' @import plotly
#' @import DT
#' @import dplyr

#' 
#' @export
performance_eval_auto <- function(data_var, list_index, ref, conf.level = 0.95, index_names = NULL, labels = "Test", forest_plot = TRUE, table_output = TRUE, file_name = "performance_eval", data_long = FALSE,  group_var = NULL){
  if(data_long == FALSE & table_output == TRUE & forest_plot == FALSE){
    return_object <- multi_sen_spe_dt_out(data_var=data_var, list_index=list_index, ref=ref, conf.level = conf.level, index_names = index_names, file_name=file_name)
  } else if(data_long == FALSE & table_output == FALSE & forest_plot == TRUE){
    plots <- multi_sen_spe_out_forest(data_var = data_var, list_index = list_index, ref = ref, conf.level = conf.level, index_names = index_names, labels = labels)
    return_object <-  list("sen_plot" = plots[[1]], "spe_plot" = plots[[2]])
  } else if (data_long == FALSE & table_output == FALSE & forest_plot == FALSE) {
    return_object <- multi_sen_spe_forest(data_var = data_var, list_index = list_index, ref = ref, conf.level = conf.level, index_names = index_names)
  } else if (data_long == FALSE & table_output == TRUE & forest_plot == TRUE){
     plots <- multi_sen_spe_out_forest(data_var = data_var, list_index = list_index, ref = ref, conf.level = conf.level, index_names = index_names, labels = labels)
     dt_table <- multi_sen_spe_dt_out(data_var=data_var, list_index=list_index, ref=ref, conf.level = conf.level, index_names = index_names, file_name=file_name)
     return_object<- list("sen_plot" = plots[[1]], "spe_plot" = plots[[2]], "table" = dt_table)
  } else if(data_long == TRUE & table_output == TRUE & forest_plot == FALSE){
    long_table <- data_var %>% 
      group_by({{group_var}}) %>% 
      group_modify( ~ sens_spe( data_var = (.x), index = list_index,  ref = ref, conf.level = conf.level))
      colnames(long_table)[1] <- labels
      
      return_object <- datatable(long_table,
          extensions = 'Buttons',
                options = list(dom = 'Blfrtip',
                               buttons = list(
                                 list(extend = 'copy', filename = file_name),
                                 list(extend = 'csv', filename = file_name),
                                 list(extend = 'excel', filename = file_name),
                                 list(extend = 'pdf', filename = file_name)),
                               lengthMenu = list(c(10,-1),
                                                 c(10,"All"))))
      
  } else if(data_long == TRUE & table_output == FALSE & forest_plot == TRUE){
    long_table <- data_var %>% 
      group_by({{group_var}}) %>% 
      group_modify( ~ sens_spe_for_forest( data_var = (.x), index = list_index,  ref = ref, conf.level = conf.level))
      colnames(long_table)[1] <- "Test"
      
      fp_sen <- ggplot(data=long_table, aes(x=Test, y=Sensitivity, ymin=SensLower, ymax=SensUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Sensitivity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)

      fp_spe <- ggplot(data=long_table, aes(x=Test, y=Specificity, ymin=SpeLower, ymax=SpeUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Specificity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)

        return_object <-  list("sen_plot" =ggplotly(fp_sen), "spe_plot" = (fp_spe))
      
  } else if(data_long == TRUE & table_output == FALSE & forest_plot == FALSE) {
    return_object <- data_var %>% 
      group_by({{group_var}}) %>% 
      group_modify( ~ sens_spe_for_forest( data_var = (.x), index = list_index,  ref = ref, conf.level = conf.level))
      colnames(return_object)[1] <- "Test"
  } else if(data_long == TRUE & table_output == TRUE & forest_plot == TRUE){
    
  long_table <- data_var %>% 
      group_by({{group_var}}) %>% 
      group_modify( ~ sens_spe( data_var = (.x), index = list_index,  ref = ref, conf.level = conf.level))
      colnames(long_table)[1] <- labels
      
      dt_table <- datatable(long_table,
          extensions = 'Buttons',
                options = list(dom = 'Blfrtip',
                               buttons = list(
                                 list(extend = 'copy', filename = file_name),
                                 list(extend = 'csv', filename = file_name),
                                 list(extend = 'excel', filename = file_name),
                                 list(extend = 'pdf', filename = file_name)),
                               lengthMenu = list(c(10,-1),
                                                 c(10,"All"))))
      
      long_table <- data_var %>% 
      group_by({{group_var}}) %>% 
      group_modify( ~ sens_spe_for_forest( data_var = (.x), index = list_index,  ref = ref, conf.level = conf.level))
      colnames(long_table)[1] <- "Test"
      
      fp_sen <- ggplot(data=long_table, aes(x=Test, y=Sensitivity, ymin=SensLower, ymax=SensUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Sensitivity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)

      fp_spe <- ggplot(data=long_table, aes(x=Test, y=Specificity, ymin=SpeLower, ymax=SpeUpper)) +
        geom_pointrange() + 
        coord_flip() +
        xlab(labels) + ylab("Specificity (95% CI)") +
        theme_classic() +
        scale_y_continuous(limits = c(0, 100),breaks = c(0, 20, 40, 60, 80, 100))+
        geom_point(size = 2, shape = 15)

        return_object <-  list("sen_plot" =ggplotly(fp_sen), "spe_plot" = (fp_spe), "table" = dt_table)
  
  }
  return(return_object)
}
```
  
```{r example-performance_eval_auto}
df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)))

# All outputs
eval_output <- performance_eval_auto(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, index_names = c("Tgs1", "AFD", "SimpleDx"), labels = "Test", forest_plot = TRUE, table_output = TRUE, file_name = "MyEvaluationExample")
eval_output$sen_plot 
eval_output$spe_plot
eval_output$table

# Forest plot outputs
eval_output_only_forest <- performance_eval_auto(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, index_names = c("Tgs1", "AFD", "SimpleDx"), labels = "Test", forest_plot = TRUE, table_output = FALSE)
eval_output_only_forest$sen_plot
eval_output_only_forest$spe_plot
eval_output_only_forest$table #NULL

# A simple data frame output where the table is not formatted. This form is computer friendly.
eval_output_simple_df <- performance_eval_auto(data_var = df, list_index = c("Index1", "Index2", "Index3"), ref = "Reference", conf.level = 0.95, index_names = c("Tgs1", "AFD", "SimpleDx"), labels = "Test", forest_plot = FALSE, table_output = FALSE)

eval_output_simple_df


# Performance Evaluation by Groups
data(my_dataset)
head(my_dataset)
eval_output <- performance_eval_auto(data_var = my_dataset, list_index = "Result", ref = "RefTest", conf.level = 0.95, labels = "Test", forest_plot = FALSE, table_output = TRUE, file_name = "MyEvaluationExample", data_long = TRUE, group_var = Test_Name )

```
  
```{r tests-performance_eval_auto}
data(my_dataset)
test_that("performance_eval_auto works", {
  expect_true(is.data.frame(performance_eval_auto(data_var = my_dataset, list_index = "Result", ref = "RefTest", conf.level = 0.95, labels = "Test", forest_plot = FALSE, table_output = FALSE, file_name = "MyEvaluationExample", data_long = TRUE, group_var = Test_Name ))) 
})
```
  
# compare_sen_spe

Comparison of sensitivities or specificities between two independent (i.e. unpaired) groups.
    
```{r function-compare_sen_spe}
#' compare_sen_spe
#' 
#' Because these are two independent groups, a Z-score is calculated from the two proportions (i.e. sensitivities or specificities) to be compared. By default, the test is two tailed, but lower or upper tail can be specified in parameters.
#' 
#' @param s1 Sensitivity/specificity of the first group
#' @param s2 Sensitivity/specificity of the second group
#' @param n1 Total number of confirmed positives/negatives respectively in the first group
#' @param n2 Total number of confirmed positives/negatives respectively in the second group
#' @param two.sided If TRUE, equivalence is tested, if FALSE, directional inferences are made
#'
#' @return A dataframe containing Z-Score and the P-value
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#' @export
compare_sen_spe <- function(s1, s2, n1, n2, two.sided = TRUE){
  z <- (s1 - s2)/sqrt((s1*(1-s1)/n1) + (s2*(1-s2)/n2))
  Z <- -abs(z)
  p <- ifelse(two.sided == TRUE, 2*pnorm(Z), pnorm(Z))
  result <- data.frame(Statistic = c("Z", "P"), Value = c(Z, p) )

  return(result)
}
```
  
```{r example-compare_sen_spe}
result.df <- data.frame(Tests = c("Test1", "Test2"), TP = c(82, 140), FN = c(18, 60))
result.df$N <- result.df$TP +result.df$FN
result.df$sen <- result.df$TP/result.df$N
compare_sen_spe(s1 = result.df$sen[1], s2 = result.df$sen[2], n1 = result.df$N[1], n2 = result.df$N[2],two.sided = TRUE)
```
  
```{r tests-compare_sen_spe}
test_that("compare_sen_spe works", {
  expect_data_frame(compare_sen_spe(s1 = 0.07, s2 = 0.038, n1 = 374, n2 = 210))
})
```
    
# nice_table
    
```{r function-nice_table}
#' nice_table
#' 
#' To create a well formatted table from the basic data frame version of the performance characteristic table generated using dplyr for subgroup analyses, where the data is not formatted in the long format necessarily.
#' 
#' @param data_var data frame
#' @param group_name Name of the grouping variable used in subgroups
#'
#' @return A nicely formatted DT table
#' @import DT
#' @export
nice_table <- function(data_var, group_name){
      table <- as.data.frame(data_var)
      table$Group <- table[,c(group_name)]
    sens_ci_text <- paste0("[", format(table$SensLower, nsmall = 1), 
        "-", format(table$SensUpper, nsmall = 1), "]")
    spe_ci_text <- paste0("[", format(table$SpeLower, nsmall = 1), 
        "-", format(table$SpeUpper, nsmall = 1), "]")
    BA_ci_text <- paste0("[", format(table$BAlower, nsmall = 1), 
        "-", format(table$BAupper, nsmall = 1), "]")
    DOR_ci_text <- paste0("[", format(table$DORLower, nsmall = 1), 
        "-", format(table$DORUpper, nsmall = 1), "]")
  ppv_ci_text <- paste0('[', format(table$PPVLower, nsmall = 1), '-', format(table$PPVUpper, nsmall = 1), ']')
  npv_ci_text  <- paste0('[', format(table$NPVLower, nsmall = 1), '-', format(table$NPVUpper, nsmall = 1), ']')
  acc_ci_text   <- paste0('[', format(table$ACCLower, nsmall = 1), '-', format(table$ACCUpper, nsmall = 1), ']')

    
    data_to_return_1 <-
      tibble(
        Test = table$Test,
        Group = table$Group,
        N = table$N,
        TP = table$TP,
        FP = table$FP,
        FN = table$FN,
        TN = table$TN,
        Sensitivity = table$Sensitivity,
        `Sensitivity [95%CI]` = sens_ci_text,
        Specificity = table$Specificity,
        `Specificity [95%CI]` = spe_ci_text,
        `Balanced Accuracy` = table$Balanced_Accuracy,
        `B. Accuracy [95%CI]` = BA_ci_text,
        DOR = table$DOR,
        `DOR [95%CI]` = DOR_ci_text,
        `PPV [95%CI]` = ppv_ci_text,
        NPV = table$NPV,
        `NPV [95%CI]` = npv_ci_text,
        Accuracy = table$Accuracy,
        `Accuracy [95%CI]` = acc_ci_text
      )
        return_table <- datatable(data_to_return_1,
          extensions = 'Buttons',
                options = list(dom = 'Blfrtip',
                               buttons = list(
                                 list(extend = 'copy', filename = "subgroup.analysis"),
                                 list(extend = 'csv', filename = "subgroup.analysis"),
                                 list(extend = 'excel', filename = "subgroup.analysis"),
                                 list(extend = 'pdf', filename = "subgroup.analysis")),
                               lengthMenu = list(c(10,-1),
                                                 c(10,"All"))))
    return(return_table)
}

```
  
```{r example-nice_table}
library(dplyr)
df <- data.frame(Index1 = c(rep("Positive", 20), rep("Negative", 20)), Index2 = c(rep("Positive", 5), rep("Negative", 35)), Index3 = c(rep("Positive", 9), rep("Negative", 31)), Reference = c(rep("Positive", 10), rep("Negative", 30)), Sex = rep(c("M","F", "F", "M"), 10))

sex_ana <- df %>% group_by(Sex) %>% group_modify(~ performance_eval_auto(
  data_var = (.x),
  list_index =c("Index1", "Index2"),
  ref = "Reference",
  conf.level = 0.95,
  index_names = NULL,
  labels = "Test",
  forest_plot = FALSE, #!!!
  table_output = FALSE, #!!!
  file_name = "performance_eval",
  data_long = FALSE, #!!!
  group_var = NULL
))
nice_table(sex_ana, "Sex")
```
  
```{r tests-nice_table}
test_that("nice_table works", {
  expect_true(inherits(nice_table, "function")) 
})
```
  
  
  
```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_performance_evaluation.Rmd", vignette_name = "Performance Evaluation")
```
